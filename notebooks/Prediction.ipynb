{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laden der Daten und Datenaufbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_json(\"embedded_output.json\")\n",
    "output = output[output[\"embedding\"].str.len() == 300]\n",
    "output = output[output[\"WZ2008 Section\"] != \"NULL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingdf = pd.DataFrame(output['embedding'].values.tolist(), index=output.index)\n",
    "embeddingdf.columns = ['textembeddings' + str(col) for col in embeddingdf.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textembeddings0</th>\n",
       "      <th>textembeddings1</th>\n",
       "      <th>textembeddings2</th>\n",
       "      <th>textembeddings3</th>\n",
       "      <th>textembeddings4</th>\n",
       "      <th>textembeddings5</th>\n",
       "      <th>textembeddings6</th>\n",
       "      <th>textembeddings7</th>\n",
       "      <th>textembeddings8</th>\n",
       "      <th>textembeddings9</th>\n",
       "      <th>...</th>\n",
       "      <th>textembeddings290</th>\n",
       "      <th>textembeddings291</th>\n",
       "      <th>textembeddings292</th>\n",
       "      <th>textembeddings293</th>\n",
       "      <th>textembeddings294</th>\n",
       "      <th>textembeddings295</th>\n",
       "      <th>textembeddings296</th>\n",
       "      <th>textembeddings297</th>\n",
       "      <th>textembeddings298</th>\n",
       "      <th>textembeddings299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>-0.099464</td>\n",
       "      <td>0.138430</td>\n",
       "      <td>-0.139252</td>\n",
       "      <td>-0.111748</td>\n",
       "      <td>0.116443</td>\n",
       "      <td>0.160833</td>\n",
       "      <td>-0.086092</td>\n",
       "      <td>-0.017977</td>\n",
       "      <td>0.033541</td>\n",
       "      <td>0.096816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027577</td>\n",
       "      <td>-0.014572</td>\n",
       "      <td>0.132774</td>\n",
       "      <td>0.199758</td>\n",
       "      <td>-0.074856</td>\n",
       "      <td>-0.077762</td>\n",
       "      <td>-0.186939</td>\n",
       "      <td>0.116442</td>\n",
       "      <td>0.053129</td>\n",
       "      <td>0.187582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>-0.156383</td>\n",
       "      <td>0.201883</td>\n",
       "      <td>-0.074046</td>\n",
       "      <td>-0.153793</td>\n",
       "      <td>0.169657</td>\n",
       "      <td>0.169687</td>\n",
       "      <td>-0.117523</td>\n",
       "      <td>-0.056078</td>\n",
       "      <td>0.012386</td>\n",
       "      <td>0.099699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>-0.056808</td>\n",
       "      <td>0.154579</td>\n",
       "      <td>0.190569</td>\n",
       "      <td>-0.047787</td>\n",
       "      <td>-0.050849</td>\n",
       "      <td>-0.162833</td>\n",
       "      <td>0.065777</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>0.171045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>-0.137489</td>\n",
       "      <td>0.183891</td>\n",
       "      <td>-0.091316</td>\n",
       "      <td>-0.148726</td>\n",
       "      <td>0.142673</td>\n",
       "      <td>0.196547</td>\n",
       "      <td>-0.110675</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.067411</td>\n",
       "      <td>0.073013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032058</td>\n",
       "      <td>-0.070422</td>\n",
       "      <td>0.093285</td>\n",
       "      <td>0.197763</td>\n",
       "      <td>-0.074207</td>\n",
       "      <td>-0.065621</td>\n",
       "      <td>-0.144966</td>\n",
       "      <td>0.072028</td>\n",
       "      <td>-0.008562</td>\n",
       "      <td>0.121606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>-0.128996</td>\n",
       "      <td>0.085962</td>\n",
       "      <td>-0.147864</td>\n",
       "      <td>-0.176685</td>\n",
       "      <td>0.105274</td>\n",
       "      <td>0.109168</td>\n",
       "      <td>-0.133889</td>\n",
       "      <td>0.022752</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>0.116291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005294</td>\n",
       "      <td>0.033829</td>\n",
       "      <td>0.090801</td>\n",
       "      <td>0.218233</td>\n",
       "      <td>-0.122840</td>\n",
       "      <td>-0.112638</td>\n",
       "      <td>-0.114931</td>\n",
       "      <td>0.091124</td>\n",
       "      <td>0.031792</td>\n",
       "      <td>0.075483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>-0.097746</td>\n",
       "      <td>0.272223</td>\n",
       "      <td>-0.062800</td>\n",
       "      <td>-0.095971</td>\n",
       "      <td>0.200952</td>\n",
       "      <td>0.363097</td>\n",
       "      <td>-0.018803</td>\n",
       "      <td>-0.041603</td>\n",
       "      <td>0.071759</td>\n",
       "      <td>0.042882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>-0.143989</td>\n",
       "      <td>0.207705</td>\n",
       "      <td>0.124247</td>\n",
       "      <td>0.092007</td>\n",
       "      <td>-0.042694</td>\n",
       "      <td>-0.266749</td>\n",
       "      <td>0.107528</td>\n",
       "      <td>-0.057326</td>\n",
       "      <td>0.147409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       textembeddings0  textembeddings1  textembeddings2  textembeddings3  \\\n",
       "10000        -0.099464         0.138430        -0.139252        -0.111748   \n",
       "10001        -0.156383         0.201883        -0.074046        -0.153793   \n",
       "10002        -0.137489         0.183891        -0.091316        -0.148726   \n",
       "10004        -0.128996         0.085962        -0.147864        -0.176685   \n",
       "10005        -0.097746         0.272223        -0.062800        -0.095971   \n",
       "\n",
       "       textembeddings4  textembeddings5  textembeddings6  textembeddings7  \\\n",
       "10000         0.116443         0.160833        -0.086092        -0.017977   \n",
       "10001         0.169657         0.169687        -0.117523        -0.056078   \n",
       "10002         0.142673         0.196547        -0.110675         0.000415   \n",
       "10004         0.105274         0.109168        -0.133889         0.022752   \n",
       "10005         0.200952         0.363097        -0.018803        -0.041603   \n",
       "\n",
       "       textembeddings8  textembeddings9        ...          textembeddings290  \\\n",
       "10000         0.033541         0.096816        ...                  -0.027577   \n",
       "10001         0.012386         0.099699        ...                   0.001862   \n",
       "10002         0.067411         0.073013        ...                  -0.032058   \n",
       "10004         0.016510         0.116291        ...                  -0.005294   \n",
       "10005         0.071759         0.042882        ...                   0.000550   \n",
       "\n",
       "       textembeddings291  textembeddings292  textembeddings293  \\\n",
       "10000          -0.014572           0.132774           0.199758   \n",
       "10001          -0.056808           0.154579           0.190569   \n",
       "10002          -0.070422           0.093285           0.197763   \n",
       "10004           0.033829           0.090801           0.218233   \n",
       "10005          -0.143989           0.207705           0.124247   \n",
       "\n",
       "       textembeddings294  textembeddings295  textembeddings296  \\\n",
       "10000          -0.074856          -0.077762          -0.186939   \n",
       "10001          -0.047787          -0.050849          -0.162833   \n",
       "10002          -0.074207          -0.065621          -0.144966   \n",
       "10004          -0.122840          -0.112638          -0.114931   \n",
       "10005           0.092007          -0.042694          -0.266749   \n",
       "\n",
       "       textembeddings297  textembeddings298  textembeddings299  \n",
       "10000           0.116442           0.053129           0.187582  \n",
       "10001           0.065777           0.006405           0.171045  \n",
       "10002           0.072028          -0.008562           0.121606  \n",
       "10004           0.091124           0.031792           0.075483  \n",
       "10005           0.107528          -0.057326           0.147409  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "abschnitte = pd.read_json(\"../abschnittsembeddings.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_distances = []\n",
    "for index, textembedding  in embeddingdf.iterrows():\n",
    "    arr = []\n",
    "    for abschnittembedding in abschnitte.iterrows(): \n",
    "        arr.append(cosine(textembedding, abschnittembedding[1]))\n",
    "    cosine_distances.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cddf = pd.DataFrame(cosine_distances, index=embeddingdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cddf.columns = [str(col) + '_cosdist' for col in cddf.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtembdist = embeddingdf.join(cddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Screenshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./screenshots/B/www.basalt.de.png\" alt=\"drawing\" width=\"250\"/> <img src=\"./screenshots/A/www.zentis.de.png\" alt=\"drawing\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embimgdata = pd.read_json(\"embedded_images_output.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagedataset = pd.DataFrame(embimgdata['imagefeatures'].apply(lambda x: x[0]).values.tolist(), index=embimgdata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagedataset.columns = ['screenshot' + str(col) for col in imagedataset.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtembdistimg = txtembdist.join(imagedataset, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtembdistimg = txtembdistimg.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prädiktion der Abschnitte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(txtembdistimg, output[\"WZ2008 Section\"].astype(str), test_size=0.1, shuffle=True, random_state=42)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prädiktion mit Screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgonly_classifier = RandomForestClassifier(n_estimators=350)\n",
    "imgonly_classifier.fit(X_train[[col for col in X_train if col.startswith('screenshot')]], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgonly_classifier.score(X_test[[col for col in X_train if col.startswith('screenshot')]], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prädiktion mit Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textembonly = RandomForestClassifier(n_estimators=400)\n",
    "textembonly.fit(X_train[[col for col in X_train if col.startswith('textembeddings')]], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.453125"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textembonly.score(X_test[[col for col in X_train if col.startswith('textembeddings')]], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prädiktion mit Description Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descdistonly = RandomForestClassifier(n_estimators=350)\n",
    "descdistonly.fit(X_train[[col for col in X_train if col.endswith('cosdist')]], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4625"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descdistonly.score(X_test[[col for col in X_train if col.endswith('cosdist')]], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = imgonly_classifier.predict_proba(X_test[[col for col in X_train if col.startswith('screenshot')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = textembonly.predict_proba(X_test[[col for col in X_train if col.startswith('textembeddings')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = descdistonly.predict_proba(X_test[[col for col in X_train if col.endswith('cosdist')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(a, b, c):\n",
    "    prediction = np.mean((a*i,b*t,c*d), axis=0).argmax(axis=1)\n",
    "    vfunc = np.vectorize(lambda x: textembonly.classes_[x])\n",
    "    prediction = vfunc(prediction)\n",
    "    return accuracy_score(prediction, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms = []\n",
    "accuracies = []\n",
    "for _ in range(10000):\n",
    "    a, b, c = [random(), random(), random()]\n",
    "    z = a+b+c\n",
    "    a = a/z\n",
    "    b = b/z\n",
    "    c = c/z\n",
    "    randoms.append([a,b,c])\n",
    "    accuracies.append(acc(a,b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46875"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(accuracies).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2743"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(accuracies).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11129243300450602, 0.24206041716784832, 0.6466471498276457]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randoms[2743]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenaufbereitung zur Vorhersage der Abteilungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['Abteilung'] = output[\"WZ2008 Code\"].astype(str).str.strip().str.split(\".\", expand=True)[0]\n",
    "output['Gruppe'] = output['Abteilung'].astype(str).map(str) + \".\" + output[\"WZ2008 Code\"].astype(str).str.strip().str.split(\".\", expand=True)[1].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "abteilungen = pd.read_json(\"../abteilungsembeddings.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_distances = []\n",
    "for index, textembedding  in embeddingdf.iterrows():\n",
    "    arr = []\n",
    "    for abteilungsembedding in abteilungen.iterrows(): \n",
    "        arr.append(cosine(textembedding, abteilungsembedding[1]))\n",
    "    cosine_distances.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "abtdf = pd.DataFrame(cosine_distances, index=embeddingdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "abtdf.columns = [str(col) + '_cosdist_abt' for col in abtdf.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtembdistimg_abt = txtembdistimg.join(abtdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prädiktion der Abteilungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(txtembdistimg_abt, output[\"Abteilung\"].astype(str), test_size=0.1, shuffle=True, random_state=42)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prädiktion mit Screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgonly_classifier.fit(X_train[[col for col in X_train if col.startswith('screenshot')]], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0984375"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgonly_classifier.score(X_test[[col for col in X_train if col.startswith('screenshot')]], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prädiktion mit Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textembonly.fit(X_train[[col for col in X_train if col.startswith('textembeddings')]], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1984375"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textembonly.score(X_test[[col for col in X_train if col.startswith('textembeddings')]], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prädiktion mit Description Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description Distances \"Abschnitte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descdistonly.fit(X_train[[col for col in X_train if col.endswith('cosdist')]], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1890625"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descdistonly.score(X_test[[col for col in X_train if col.endswith('cosdist')]], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description Distances \"Abteilungen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "descdistonly_abteilungen = RandomForestClassifier(n_estimators=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2078125"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descdistonly_abteilungen.fit(X_train[[col for col in X_train if col.endswith('cosdist_abt')]], Y_train)\n",
    "descdistonly_abteilungen.score(X_test[[col for col in X_train if col.endswith('cosdist_abt')]], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = imgonly_classifier.predict_proba(X_test[[col for col in X_train if col.startswith('screenshot')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = textembonly.predict_proba(X_test[[col for col in X_train if col.startswith('textembeddings')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = descdistonly.predict_proba(X_test[[col for col in X_train if col.endswith('cosdist')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_abt = descdistonly_abteilungen.predict_proba(X_test[[col for col in X_train if col.endswith('cosdist_abt')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(a, b, c, e):\n",
    "    prediction = np.mean((a*i,b*t,c*d, d_abt*e), axis=0).argmax(axis=1)\n",
    "    vfunc = np.vectorize(lambda x: textembonly.classes_[x])\n",
    "    prediction = vfunc(prediction)\n",
    "    return accuracy_score(prediction, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "randoms = []\n",
    "accuracies = []\n",
    "for _ in range(10000):\n",
    "    a, b, c, e = [random(), random(), random(), random()]\n",
    "    z = a+b+c+e\n",
    "    a = a/z\n",
    "    b = b/z\n",
    "    c = c/z\n",
    "    e = e/z\n",
    "    randoms.append([a,b,c,e])\n",
    "    accuracies.append(acc(a,b,c,e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21875"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(accuracies).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5354"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(accuracies).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03639304471958594,\n",
       " 0.6096533456360916,\n",
       " 0.09914855130933253,\n",
       " 0.25480505833498984]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randoms[5354]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenaufbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_embeddings = pd.read_json('wiki_embedding.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_tmp = pd.DataFrame(wiki_embeddings['embedding'].values.tolist(), index=wiki_embeddings.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_tmp.columns = [str(col) + '_wiki' for col in wiki_tmp.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_embeddings = wiki_embeddings.join(wiki_tmp, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"url\"] = output[\"url\"].str.replace(\"https://\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_embeddings = wiki_embeddings.merge(output, how=\"left\", on=\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_embeddings = wiki_embeddings[wiki_embeddings[\"text\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prädiktion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(wiki_embeddings, wiki_embeddings[\"WZ2008 Code\"].astype(str), test_size=0.1, shuffle=True, random_state=42)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_rf = RandomForestClassifier(n_estimators=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_rf.fit(X_train[[col for col in X_train if col.endswith('wiki')]], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3137254901960784"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_rf.score(X_test[[col for col in X_train if col.endswith('wiki')]], Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_distances = []\n",
    "for index, textembedding  in wiki_embeddings[[col for col in X_train if col.endswith('wiki')]].iterrows():\n",
    "    arr = []\n",
    "    for abschnittembedding in abschnitte.iterrows(): \n",
    "        arr.append(cosine(textembedding, abschnittembedding[1]))\n",
    "    cosine_distances.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_cddf = pd.DataFrame(cosine_distances, index=wiki_embeddings.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_cddf.columns = [str(col) + '_cosdist_wiki' for col in wiki_cddf.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_embeddings = wiki_embeddings.join(wiki_cddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(wiki_embeddings, wiki_embeddings[\"WZ2008 Code\"].astype(str), test_size=0.1, shuffle=True, random_state=42)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_rfdist = RandomForestClassifier(n_estimators=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=350, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_rfdist.fit(X_train[[col for col in X_train if col.endswith('_cosdist_wiki')]], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29411764705882354"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_rfdist.score(X_test[[col for col in X_train if col.endswith('_cosdist_wiki')]], Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.92      0.95        39\n",
      "           2       0.95      1.00      0.97        36\n",
      "           3       1.00      0.97      0.98        31\n",
      "           4       0.92      0.97      0.95        36\n",
      "           5       0.96      0.98      0.97        45\n",
      "           6       0.97      1.00      0.99        33\n",
      "           7       0.92      1.00      0.96        35\n",
      "           8       1.00      0.89      0.94        38\n",
      "           9       1.00      0.94      0.97        31\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       324\n",
      "   macro avg       0.97      0.96      0.96       324\n",
      "weighted avg       0.96      0.96      0.96       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn_hierarchical_classification.classifier import HierarchicalClassifier\n",
    "from sklearn_hierarchical_classification.constants import ROOT\n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "\n",
    "def make_digits_dataset(targets=None, as_str=True):\n",
    "    X, y = load_digits(return_X_y=True)\n",
    "    if targets:\n",
    "        ix = np.isin(y, targets)\n",
    "        X, y = X[np.where(ix)], y[np.where(ix)]\n",
    "\n",
    "    if as_str:\n",
    "        # Convert targets (classes) to strings\n",
    "        y = y.astype(str)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Used for seeding random state\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "class_hierarchy = {\n",
    "    ROOT: [\"A\", \"B\"],\n",
    "    \"A\": [\"C\", \"D\"],\n",
    "    \"B\": [\"E\", \"F\", \"G\"],\n",
    "    \"C\": [9],\n",
    "    \"D\": [1,5],\n",
    "    \"E\": [2,3],\n",
    "    \"F\": [4,6],\n",
    "    \"G\": [7,8],\n",
    "}\n",
    "base_estimator = make_pipeline(\n",
    "    RandomForestClassifier(n_estimators=100)\n",
    ")\n",
    "clf = HierarchicalClassifier(\n",
    "    base_estimator=base_estimator,\n",
    "    class_hierarchy=class_hierarchy,\n",
    ")\n",
    "X, y = make_digits_dataset(\n",
    "    targets=[1, 2,3,4,5,6,7,8,9],\n",
    "    as_str=False,\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
